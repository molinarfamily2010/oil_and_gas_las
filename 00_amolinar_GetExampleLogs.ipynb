{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Log ASCII Standard (LAS) Files: A Walkthrough\n",
    "\n",
    "We aim to normalize unstructured LAS files, commonly used in the oil and gas industry. LAS files can be complex and challenging due to inconsistent naming conventions and varied units. This notebook is part 1 of our data science approach to handle these complexities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting up the environment\n",
    "\n",
    "We start by ensuring that the requests library is installed. This library will allow us to send HTTP requests for downloading the required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we import the necessary libraries for our project:\n",
    "\n",
    "    pandas -> for data manipulation and analysis,\n",
    "    requests -> for sending HTTP requests,\n",
    "    zipfile -> for extracting ZIP files, and\n",
    "    io -> to handle file streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Downloading the LAS files\n",
    "\n",
    "This cell sets up a flag to control whether to re-download the dataset or not. This is useful for controlling data usage and avoiding unnecessary downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "redownload = False\n",
    "\n",
    "if redownload:\n",
    "    url = \"https://www.kgs.ku.edu/PRS/Ora_Archive/ks_las_files.zip\"\n",
    "    response = requests.get(url)\n",
    "    zip_file = io.BytesIO(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_file) as z:\n",
    "        z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_file_df = pd.read_csv('ks_las_files.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KGS_ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Lease</th>\n",
       "      <th>API</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Elev_Ref</th>\n",
       "      <th>Depth_start</th>\n",
       "      <th>Depth_stop</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1028187622</td>\n",
       "      <td>39.983440</td>\n",
       "      <td>-97.199375</td>\n",
       "      <td>T1S R2E, Sec. 10,   NW SW NW</td>\n",
       "      <td>KANSAS GEOLOGICAL SURVEY</td>\n",
       "      <td>W. GAYDUSEK II 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>KB</td>\n",
       "      <td>50.5</td>\n",
       "      <td>525.0</td>\n",
       "      <td>http://www.kgs.ku.edu/WellLogs/01S02E/10200690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044172351</td>\n",
       "      <td>39.943543</td>\n",
       "      <td>-95.936294</td>\n",
       "      <td>T1S R13E, Sec. 23,  W2 SE SW SW</td>\n",
       "      <td>Kinney Oil Company</td>\n",
       "      <td>Baumgartner 1-23 1</td>\n",
       "      <td>15-131-20234</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>KB</td>\n",
       "      <td>1814.2</td>\n",
       "      <td>2096.2</td>\n",
       "      <td>http://www.kgs.ku.edu/WellLogs/kcc_logs_2015/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044172351</td>\n",
       "      <td>39.943543</td>\n",
       "      <td>-95.936294</td>\n",
       "      <td>T1S R13E, Sec. 23,  W2 SE SW SW</td>\n",
       "      <td>Kinney Oil Company</td>\n",
       "      <td>Baumgartner 1-23 1</td>\n",
       "      <td>15-131-20234</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>KB</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2096.4</td>\n",
       "      <td>http://www.kgs.ku.edu/WellLogs/kcc_logs_2015/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1044022696</td>\n",
       "      <td>39.992205</td>\n",
       "      <td>-95.799079</td>\n",
       "      <td>T1S R14E, Sec. 1,  SW NE NE SW</td>\n",
       "      <td>Wolf Operating LLC</td>\n",
       "      <td>Stalder-Adams 1-1</td>\n",
       "      <td>15-131-20225</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>KB</td>\n",
       "      <td>185.2</td>\n",
       "      <td>3663.2</td>\n",
       "      <td>http://www.kgs.ku.edu/WellLogs/kcc_logs_2014/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044022696</td>\n",
       "      <td>39.992205</td>\n",
       "      <td>-95.799079</td>\n",
       "      <td>T1S R14E, Sec. 1,  SW NE NE SW</td>\n",
       "      <td>Wolf Operating LLC</td>\n",
       "      <td>Stalder-Adams 1-1</td>\n",
       "      <td>15-131-20225</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>KB</td>\n",
       "      <td>3319.6</td>\n",
       "      <td>3663.6</td>\n",
       "      <td>http://www.kgs.ku.edu/WellLogs/kcc_logs_2014/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       KGS_ID   Latitude  Longitude                         Location  \\\n",
       "0  1028187622  39.983440 -97.199375     T1S R2E, Sec. 10,   NW SW NW   \n",
       "1  1044172351  39.943543 -95.936294  T1S R13E, Sec. 23,  W2 SE SW SW   \n",
       "2  1044172351  39.943543 -95.936294  T1S R13E, Sec. 23,  W2 SE SW SW   \n",
       "3  1044022696  39.992205 -95.799079   T1S R14E, Sec. 1,  SW NE NE SW   \n",
       "4  1044022696  39.992205 -95.799079   T1S R14E, Sec. 1,  SW NE NE SW   \n",
       "\n",
       "                   Operator               Lease           API  Elevation  \\\n",
       "0  KANSAS GEOLOGICAL SURVEY    W. GAYDUSEK II 1           NaN     1599.0   \n",
       "1        Kinney Oil Company  Baumgartner 1-23 1  15-131-20234     1215.0   \n",
       "2        Kinney Oil Company  Baumgartner 1-23 1  15-131-20234     1215.0   \n",
       "3        Wolf Operating LLC   Stalder-Adams 1-1  15-131-20225     1130.0   \n",
       "4        Wolf Operating LLC   Stalder-Adams 1-1  15-131-20225     1130.0   \n",
       "\n",
       "  Elev_Ref  Depth_start  Depth_stop  \\\n",
       "0       KB         50.5       525.0   \n",
       "1       KB       1814.2      2096.2   \n",
       "2       KB        240.0      2096.4   \n",
       "3       KB        185.2      3663.2   \n",
       "4       KB       3319.6      3663.6   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://www.kgs.ku.edu/WellLogs/01S02E/10200690...  \n",
       "1  http://www.kgs.ku.edu/WellLogs/kcc_logs_2015/1...  \n",
       "2  http://www.kgs.ku.edu/WellLogs/kcc_logs_2015/1...  \n",
       "3  http://www.kgs.ku.edu/WellLogs/kcc_logs_2014/1...  \n",
       "4  http://www.kgs.ku.edu/WellLogs/kcc_logs_2014/1...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las_file_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Normalizing the List\n",
    "\n",
    "1. We split the 'Location' column from the DataFrame into individual components. \n",
    "\n",
    "2. Then we clean up the data by replacing comma characters with nothing, and combine the 'Township' and 'Range' columns to form a new 'Township-Range' column. \n",
    "\n",
    "3. We merge this cleaned and transformed data back into the original DataFrame and drop the original 'Location' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = las_file_df.Location.str.split(' ', expand = True)\n",
    "location_df.columns = ['Township', 'Range', '', 'Section', '',  \"QC4\", \"QC3\", \"QC2\", \"QC1\", '']\n",
    "columns_to_keep = ['Township', 'Range', 'Section', \"QC4\", \"QC3\", \"QC2\", \"QC1\"]\n",
    "location_df = location_df[columns_to_keep]\n",
    "location_df = location_df.replace(',', '', regex=True)\n",
    "location_df['Township-Range'] = location_df['Township'] + '-' + location_df['Range']\n",
    "las_file_df = las_file_df.merge(location_df, left_index=True, right_index=True)\n",
    "las_file_df = las_file_df.drop('Location', axis = 'columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Focusing on a specific Township and Range\n",
    "\n",
    "Due to the large size of the dataset, we filter it down to a specific 'Township-Range' for a manageable and focused analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T20S-R20E    267\n",
       "T32S-R12W    231\n",
       "T31S-R1W     197\n",
       "T14S-R32W    160\n",
       "T11S-R17W    160\n",
       "            ... \n",
       "T13S-R10W      1\n",
       "T13S-R9W       1\n",
       "T12S-R41W      1\n",
       "T12S-R40W      1\n",
       "T15S-R39W      1\n",
       "Name: Township-Range, Length: 1618, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df['Township-Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T20S-R20E'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_mask_value = location_df['Township-Range'].value_counts().idxmax()\n",
    "tr_mask_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = las_file_df['Township-Range'] == tr_mask_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = las_file_df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Downloading the filtered data\n",
    "\n",
    "We define a function to download a ZIP file from a specified URL and extract it into a specified location.\n",
    "\n",
    "If the redownload flag is set to True, we loop through each row of the filtered DataFrame, construct the URL and filename for the ZIP file, and then download and extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip(url, filename):\n",
    "    response = requests.get(url) \n",
    "    zip_file = io.BytesIO(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_file) as z:\n",
    "        z.extractall(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if redownload:\n",
    "    for idx, row in target_df.iterrows():\n",
    "        folder = row.KGS_ID\n",
    "        url = row.URL\n",
    "        zip_num = url.split('/')[-1].strip('.zip')\n",
    "        filename = f'logs/{folder}/{zip_num}/'\n",
    "        get_zip(url, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of Part 1 of our walkthrough, where we load, normalize and filter the data. \n",
    "\n",
    "In subsequent parts, we will continue with depth adjustment, splicing, and outputting the logs in a format ready for geological workstation software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51a9663a131f1b5758c45b97a2d6917c8ae86b33e231c3733631cbc7265cfc89"
  },
  "kernelspec": {
   "display_name": "Python 3.6.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
